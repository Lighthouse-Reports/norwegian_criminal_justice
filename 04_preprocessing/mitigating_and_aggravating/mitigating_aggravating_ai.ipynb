{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from openai import AzureOpenAI, BadRequestError\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "import logging\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "from mitigating_aggravating_ai_lists import aggravating_list, mitigating_list\n",
    "from bson import ObjectId\n",
    "import json\n",
    "from config import db_config\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(os.path.abspath(os.path.join(os.getcwd(), \"../config/.env\")))\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_VERSION\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/henrik.boe/repos/Github/smeinrich/dommedag/venv/lib/python3.11/site-packages/transformers/configuration_utils.py:365: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Hugging Face config\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"NbAiLab/nb-bert-base-ner\", model_max_length=512)\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"NbAiLab/nb-bert-base-ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "COL_LOCAL_DOMMER = db_config.DB_LOCAL_DOMMEDAG[\"dommer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports judgements from the database or from a json file.\n",
    "def import_judgements(from_file: bool = False, file_path: str = \"../input/judgements.json\") -> list | pymongo.cursor.Cursor:\n",
    "    if from_file:\n",
    "        with open(file_path, \"r\") as f:\n",
    "            return json.load(f)\n",
    "    else:\n",
    "        return COL_LOCAL_DOMMER.find(no_cursor_timeout=True)\n",
    "\n",
    "\n",
    "# Updates judgements in the database or json file.\n",
    "def update_judgement(judgements: list, judgement_id: str, circumstance_types: list, mitigating_or_aggravating: str, to_file: bool = False, file_path: str = \"../input/judgements.json\"):\n",
    "    if to_file:\n",
    "        for judgement in judgements:\n",
    "            if judgement[\"_id\"] == judgement_id:\n",
    "                judgement[mitigating_or_aggravating] = circumstance_types\n",
    "                break\n",
    "        with open(file_path, 'w') as file:\n",
    "            json.dump(judgements, file, indent=4)\n",
    "    else:\n",
    "        COL_LOCAL_DOMMER.update_one(\n",
    "            {'_id': ObjectId(judgement_id)},\n",
    "            {'$push': {mitigating_or_aggravating: circumstance_types}}\n",
    "        )\n",
    "\n",
    "\n",
    "# Splits the string into paragraphs using two newlines, including whitespace between them, as a separator\n",
    "def get_paragraphs(str):\n",
    "    paragraphs = re.split(r\"\\n\\s*\\n\", str)\n",
    "    return paragraphs\n",
    "\n",
    "\n",
    "def is_analyzed(collection):\n",
    "  # Check if \"skjerpende_formildende_sjekket\" field exists and is True\n",
    "  return collection.get(\"skjerpende_formildende_sjekket\", False) == True\n",
    "\n",
    "\n",
    "\n",
    "def get_ai_response(system_prompt, user_example_1, assistant_example_1, user_example_2, assistant_example_2, user_example_3, assistant_example_3, paragraph):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"nrkddivundersokendesorost1106\",\n",
    "        response_format={ \"type\": \"json_object\" },\n",
    "        messages = [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": system_prompt\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": user_example_1\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": assistant_example_1\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": user_example_2\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": assistant_example_2\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": user_example_3\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": assistant_example_3\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": paragraph\n",
    "                },\n",
    "            ],\n",
    "        temperature=0,\n",
    "        max_tokens=2000,)\n",
    "    \n",
    "    response = completion.choices[0].message.content\n",
    "    time.sleep(3)\n",
    "    return json.loads(response)\n",
    "\n",
    "\n",
    "# Replaces names in a string with only the text \"Navn\".\n",
    "def replace_names_with_placeholder(input_str):\n",
    "    nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "    ner_results = nlp(input_str)\n",
    "    reversed_ner_results = list(reversed(ner_results))\n",
    "\n",
    "    for entity in reversed_ner_results:\n",
    "        if entity[\"entity\"] == \"B-PER\":\n",
    "            if \"##\" in entity[\"word\"]:\n",
    "                input_str = input_str[:entity[\"start\"]] + \\\n",
    "                    input_str[entity[\"end\"]:]\n",
    "            else:\n",
    "                input_str = input_str[:entity[\"start\"]] + \"Navn\" + input_str[entity[\"end\"]:]\n",
    "        elif entity[\"entity\"] == \"I-PER\":\n",
    "            if \"##\" in entity[\"word\"]:\n",
    "                input_str = input_str[:entity[\"start\"]] + \\\n",
    "                    input_str[entity[\"end\"]:]\n",
    "            else:\n",
    "                input_str = input_str[:entity[\"start\"]] + input_str[entity[\"end\"]:]\n",
    "\n",
    "    return input_str.replace(\"  \", \" \")\n",
    "\n",
    "\n",
    "\n",
    "def replace_dates(text):\n",
    "    # Pattern for \"dd.mm.yyyy\" format\n",
    "    pattern1 = r\"\\d{1,2}\\.\\s?\\d{1,2}\\.\\s?\\d{4}\"\n",
    "\n",
    "    # Pattern for \"dd. month yyyy\" format\n",
    "    months = \"januar|februar|mars|april|mai|juni|juli|august|september|oktober|november|desember\"\n",
    "    pattern2 = r\"\\d{1,2}\\.\\s?(\" + months + r\")(\\s?\\d{4})?\"\n",
    "\n",
    "    # Combined pattern with an 'or' condition\n",
    "    combined_pattern = f\"({pattern1})|({pattern2})\"\n",
    "\n",
    "    return re.sub(combined_pattern, \"DATO\", text)\n",
    "\n",
    "\n",
    "def count_word(text, word):\n",
    "  text = text.lower()\n",
    "  word = word.lower()\n",
    "  words = text.split()\n",
    "  count = words.count(word)\n",
    "\n",
    "  return count\n",
    "\n",
    "# Checks if mitigating or aggravating circumstances are written in past tense.\n",
    "# Returns True if any of the past tense formulations in the list are found AND the word mitigating or aggravating is only found once in the paragraph\n",
    "def circumstance_is_in_past_tense(paragraph, mitigating=True) -> bool:\n",
    "    if mitigating:\n",
    "        if count_word(paragraph, \"formildende\") == 1 or count_word(paragraph, \"formildande\") == 1:\n",
    "            mitigating_past_tense_list = [\"var formildende\", \"var formildande\", \"forelå formildende\", \"forelå formildande\", \"formildende omstendigheter var\", \"formildande omstende var\"]\n",
    "            for string in mitigating_past_tense_list:\n",
    "                if string in paragraph:\n",
    "                    logging.info(f\"Found paragraph in past tense: {paragraph}\")\n",
    "                    return True\n",
    "        return False\n",
    "    else:\n",
    "        paragraph = paragraph.replace(\"straffeskjerpende\", \"skjerpende\")\n",
    "        paragraph = paragraph.replace(\"straffeskjerpande\", \"skjerpande\")\n",
    "        if count_word(paragraph, \"skjerpende\") == 1 or count_word(paragraph, \"skjerpande\") == 1:\n",
    "            aggravating_past_tense_list = [\"var skjerpende\", \"var skjerpande\", \"forelå skjerpende\", \"forelå skjerpande\", \"skjerpende omstendigheter var\", \"skjerpande omstende var\"]\n",
    "            for string in aggravating_past_tense_list:\n",
    "                if string in paragraph:\n",
    "                    logging.info(f\"Found paragraph in past tense: {paragraph}\")\n",
    "                    return True\n",
    "        return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_aggravating = \"\"\"\n",
    "Du er en assistent som leser korte tekstutdrag fra dommer. Du skal avgjøre om teksten inneholder informasjon om hvilke eventuelle skjerpende eller straffeskjerpende omstendigheter det er i saken. Du skal identifisere de mest relevante skjerpende eller straffeskjerpende omstendighete fra listen nedenfor.\n",
    "Du skal kun nevne omstendigheter det står at er skjerpende eller straffeskjerpende for denne dommen, ikke omstendigheter for tidligere dommer. Dersom det ikke står at omstendigheten er skjerpende eller straffeskjerpende, eller hvis teksten om omstendigheten er skrevet i fortid, skal du svare {\"skjerpende\": \"false\"}.\n",
    "Du skal svare i json-format på denne måten: {\"skjerpende\": \"drapstrusler\"}. Dersom du finner flere skjerpende omstendigheter skiller du dem med komma på denne måten: {\"skjerpende\": \"drapstrusler, trygdesvindel\"}.\n",
    "Hvis du ikke finner en relevant omstendighet i listen, svarer du {\"skjerpende\": \"andre omstendigheter\"}. Hvis det mangler informasjon om skjerpende eller straffeskjerpende omstendigheter, eller hvis du ikke klarer å tolke det, skal du svare {\"skjerpende\": \"false\"}.\n",
    "Hvis formuleringen om omstendigheten er skrevet i fortid, for eksempel \"det var skjerpende\" eller \"det forelå skjerpende\", skal du svare {\"skjerpende\": \"false\"}.\n",
    "Her er listen:\n",
    "\"\"\" + aggravating_list\n",
    "\n",
    "system_prompt_mitigating = \"\"\"\n",
    "Du er en assistent som leser korte tekstutdrag fra dommer. Du skal avgjøre om teksten inneholder informasjon om hvilke eventuelle formildende omstendigheter det er i saken. Du skal identifisere de mest relevante formildende omstendighetene fra listen nedenfor.\n",
    "Du skal kun nevne omstendigheter det står at er formildende for denne saken, ikke omstendigheter som er formildende for tidligere rettssaker. Dersom det ikke står at omstendigheten er formildende, eller hvis teksten om omstendigheten er skrevet i fortid, skal du svare {\"formildende\": \"false\"}.\n",
    "Du skal svare i json-format på denne måten: {\"formildende\": \"selvforsvar\"}. Dersom du finner flere formildende omstendigheter skiller du dem med komma på denne måten: {\"formildende\": \"selvforsvar, tilståelse\"}.\n",
    "Hvis du ikke finner en relevant omstendighet i listen, svarer du {\"formildende\": \"andre omstendigheter\"}. Hvis det mangler informasjon om formildende omstendigheter, eller hvis du ikke klarer å tolke det, skal du svare {\"formildende\": \"false\"}.\n",
    "Hvis formuleringen om omstendigheten er skrevet i fortid, for eksempel \"det var formildende\" eller \"det forelå formildende\", skal du svare {\"formildende\": \"false\"}.\n",
    "Her er listen:\n",
    "\"\"\" + mitigating_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples for aggravating paragraphs and assistant response\n",
    "\n",
    "user_example_1_aggravating = \"I skjerpende retning legger retten vekt på at Navn kjørte i ruspåvirket tilstand. Det er også skjerpende at vedkommende har utøvd psykisk vold mot fornærmede.\"\n",
    "\n",
    "assistant_example_1_aggravating = \"\"\"{\"skjerpende\": \"kjøring under ruspåvirkning, psykisk vold\"}\"\"\"\n",
    "\n",
    "user_example_2_aggravating = \"\"\"\n",
    "Navn ble ved Kristiansand tingretts dom av DATO dømt til forvaring i 16 år \n",
    "med minstetid på 10 år for overlagt drap under særdeles skjerpende omstendigheter. Etter anke ble straffen \n",
    "fastsatt til forvaring.\n",
    "\"\"\"\n",
    "\n",
    "assistant_example_2_aggravating = \"\"\"{\"skjerpende\": \"false\"}\"\"\"\n",
    "\n",
    "user_example_3_aggravating = \"\"\"\n",
    "Overtredelsen i post I ville medført en kortere betinget straff, \n",
    "og tillegges vekt i straffeskjerpende retning.\n",
    "\"\"\"\n",
    "\n",
    "assistant_example_3_aggravating = \"\"\"{\"skjerpende\": \"andre omstendigheter\"}\"\"\"\n",
    "\n",
    "# Examples for mitigating paragraphs and assistant response\n",
    "\n",
    "user_example_1_mitigating = \"I formildende retning legger retten vekt på at Navn har gitt en uforbeholden tilståelse. Det er i tillegg formildende at saksbehandlingstiden har vært lang.\"\n",
    "\n",
    "assistant_example_1_mitigating = \"\"\"{\"formildende\": \"tilståelse, lang saksbehandlingstid\"}\"\"\"\n",
    "\n",
    "user_example_2_mitigating = \"\"\"\n",
    "Saken gjaldt straffutmåling for uaktsomt heleri. Det var formildende at de domfelte \n",
    "hadde samarbeidet med politiet og møtt som vitner i saken mot hovedmannen, \n",
    "og at straffeforfølgningen hadde tatt lang tid.\n",
    "\"\"\"\n",
    "\n",
    "assistant_example_2_mitigating = \"\"\"{\"formildende\": \"false\"}\"\"\"\n",
    "\n",
    "user_example_3_mitigating = \"\"\"\n",
    "Det forelå formildende omstendigheter, ettersom hun hadde daglig omsorg for det yngste barnet. \n",
    "Dommen er etter gammel straffelov, og før strafferammen ble \n",
    "økt, men samtidig er tidsperioden lengre enn i denne sak.\n",
    "\"\"\"\n",
    "\n",
    "assistant_example_3_mitigating = \"\"\"{\"formildende\": \"false\"}\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main processing loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/henrik.boe/repos/Github/smeinrich/dommedag/venv/lib/python3.11/site-packages/pymongo/collection.py:1650: UserWarning: use an explicit session with no_cursor_timeout=True otherwise the cursor may still timeout after 30 minutes, for more info see https://mongodb.com/docs/v4.4/reference/method/cursor.noCursorTimeout/#session-idle-timeout-overrides-nocursortimeout\n",
      "  return Cursor(self, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# If importing from json file, set the first argument to True and optionally the second argument to file path (\"If file path is different than \"../input/judgements.json\"\")\n",
    "judgements = import_judgements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
